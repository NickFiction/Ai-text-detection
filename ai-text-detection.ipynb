{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":7456170,"sourceType":"datasetVersion","datasetId":4335155},{"sourceId":159219517,"sourceType":"kernelVersion"}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport gc\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom transformers import PreTrainedTokenizerFast\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import VotingClassifier","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:25.795475Z","iopub.execute_input":"2024-02-24T06:36:25.795853Z","iopub.status.idle":"2024-02-24T06:36:36.119738Z","shell.execute_reply.started":"2024-02-24T06:36:25.795823Z","shell.execute_reply":"2024-02-24T06:36:36.118536Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Explanation:**\nThis little piece of code reads data into pandas DataFrames from CSV files. Data from the test essays.csv file is contained in the test DataFrame, while data from the sample submission.csv file is contained in the sub DataFrame.","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\nsub = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n\n# train = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')\ntrain = pd.read_csv(\"/kaggle/input/daigt-v2-spellcheck/daigt-v2_spellcheck.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:36.121704Z","iopub.execute_input":"2024-02-24T06:36:36.122454Z","iopub.status.idle":"2024-02-24T06:36:38.225962Z","shell.execute_reply.started":"2024-02-24T06:36:36.122416Z","shell.execute_reply":"2024-02-24T06:36:38.224925Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = train.loc[((train['label']==0) & (train['RDizzl3_seven']==1)) | (train['label']==1)].reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:38.227337Z","iopub.execute_input":"2024-02-24T06:36:38.227926Z","iopub.status.idle":"2024-02-24T06:36:38.256956Z","shell.execute_reply.started":"2024-02-24T06:36:38.227884Z","shell.execute_reply":"2024-02-24T06:36:38.255447Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = train.drop_duplicates(subset=['text'])\ntrain.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:38.260005Z","iopub.execute_input":"2024-02-24T06:36:38.260397Z","iopub.status.idle":"2024-02-24T06:36:38.317798Z","shell.execute_reply.started":"2024-02-24T06:36:38.260346Z","shell.execute_reply":"2024-02-24T06:36:38.316487Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:38.319381Z","iopub.execute_input":"2024-02-24T06:36:38.319775Z","iopub.status.idle":"2024-02-24T06:36:38.331759Z","shell.execute_reply.started":"2024-02-24T06:36:38.319743Z","shell.execute_reply":"2024-02-24T06:36:38.330652Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(31747, 6)"},"metadata":{}}]},{"cell_type":"code","source":"train.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:38.332866Z","iopub.execute_input":"2024-02-24T06:36:38.333171Z","iopub.status.idle":"2024-02-24T06:36:38.344739Z","shell.execute_reply.started":"2024-02-24T06:36:38.333144Z","shell.execute_reply":"2024-02-24T06:36:38.343602Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"label\n1    17497\n0    14250\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"This code sample eliminates duplicate rows based on the text column, resets the DataFrame's index for consistency and clarity, and filters out rows from the train DataFrame where the prompt name is in the excluded_prompt_name_list.","metadata":{}},{"cell_type":"code","source":"excluded_prompt_name_list = ['Distance learning','Grades for extracurricular activities','Summer projects']\ntrain = train[~(train['prompt_name'].isin(excluded_prompt_name_list))]\ntrain = train.drop_duplicates(subset=['text'])\ntrain.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:38.347149Z","iopub.execute_input":"2024-02-24T06:36:38.347939Z","iopub.status.idle":"2024-02-24T06:36:38.372402Z","shell.execute_reply.started":"2024-02-24T06:36:38.347897Z","shell.execute_reply":"2024-02-24T06:36:38.371217Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"This section of code imports regular expressions, text manipulation modules, and the Levenshtein distance method; it is possible that string matching or similarity computations are part of the code that follows.","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nimport re\nfrom leven_search import LevenSearch, EditCost, EditCostConfig, GranularEditCostConfig","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:38.373740Z","iopub.execute_input":"2024-02-24T06:36:38.374068Z","iopub.status.idle":"2024-02-24T06:36:38.491734Z","shell.execute_reply.started":"2024-02-24T06:36:38.374040Z","shell.execute_reply":"2024-02-24T06:36:38.490658Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/usr/lib/install_levenshtein_search_library/leven_search.pkl', 'rb') as file:\n    lev_search = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:38.493190Z","iopub.execute_input":"2024-02-24T06:36:38.493896Z","iopub.status.idle":"2024-02-24T06:36:40.636275Z","shell.execute_reply.started":"2024-02-24T06:36:38.493861Z","shell.execute_reply":"2024-02-24T06:36:40.635270Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def sentence_correcter(text):\n    dict_freq = defaultdict(lambda :0)\n    \n    wrong_words = []\n    correct_words = dict()\n    word_list = re.findall(r'\\b\\w+\\b|[.,\\s]', text)\n    \n    for t in word_list:\n        correct_word = t\n    \n        if len(t)>2:\n            result = lev_search.find_dist(t, max_distance=0)\n            result = list(result.__dict__['words'].values())\n    \n            if len(result) == 0:\n                result = lev_search.find_dist(t, max_distance=1)\n                result = list(result.__dict__['words'].values())\n                if len(result):\n                    correct_word = result[0].word\n                    wrong_words.append((t, result))\n    \n        correct_words[t] = correct_word\n               \n    for wrong_word in wrong_words:\n        _, result = wrong_word\n    \n        for res in result:\n            updates = res.updates\n            parts = str(updates[0]).split(\" -> \")\n            if len(parts) == 2:\n                from_char = parts[0]\n                to_char = parts[1]\n                dict_freq[(from_char, to_char)] += 1\n    \n    if len(dict_freq):\n        max_key = max(dict_freq, key=dict_freq.get)\n        count = dict_freq[max_key]\n    else:\n        count = 0\n    \n    if count > 0.06*len(text.split()):\n        gec = GranularEditCostConfig(default_cost=10, edit_costs=[EditCost(max_key[0], max_key[1], 1)])\n    \n        for wrong_word in wrong_words:\n            word, _ = wrong_word\n            result = lev_search.find_dist(word, max_distance=9, edit_cost_config=gec)\n            result = list(result.__dict__['words'].values())\n            if len(result):\n                correct_words[word] = result[0].word\n            else:\n                correct_word = word\n    \n    \n    correct_sentence = []\n    for t in word_list:\n        correct_sentence.append(correct_words[t])\n    \n    return \"\".join(correct_sentence)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:40.640932Z","iopub.execute_input":"2024-02-24T06:36:40.641317Z","iopub.status.idle":"2024-02-24T06:36:40.656663Z","shell.execute_reply.started":"2024-02-24T06:36:40.641282Z","shell.execute_reply":"2024-02-24T06:36:40.655493Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"corrected_test = test.loc[:, 'text'].apply(sentence_correcter)\ntest.loc[:, 'text'] = corrected_test","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:40.658002Z","iopub.execute_input":"2024-02-24T06:36:40.658425Z","iopub.status.idle":"2024-02-24T06:36:40.679408Z","shell.execute_reply.started":"2024-02-24T06:36:40.658385Z","shell.execute_reply":"2024-02-24T06:36:40.677928Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"LOWERCASE = False\nVOCAB_SIZE = 14000000","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:40.681262Z","iopub.execute_input":"2024-02-24T06:36:40.681714Z","iopub.status.idle":"2024-02-24T06:36:40.690411Z","shell.execute_reply.started":"2024-02-24T06:36:40.681674Z","shell.execute_reply":"2024-02-24T06:36:40.689253Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Creating Byte-Pair Encoding tokenizer\nraw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n# Adding normalization and pre_tokenizer\nraw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\nraw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n# Adding special tokens and creating trainer instance\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n# Creating huggingface dataset object\ndataset = Dataset.from_pandas(test[['text']])\ndef train_corp_iter():\n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"text\"]\nraw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)\ntokenized_texts_test = []\n\nfor text in tqdm(test['text'].tolist()):\n    tokenized_texts_test.append(tokenizer.tokenize(text))\n\ntokenized_texts_train = []\n\nfor text in tqdm(train['text'].tolist()):\n    tokenized_texts_train.append(tokenizer.tokenize(text))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:36:40.691872Z","iopub.execute_input":"2024-02-24T06:36:40.692316Z","iopub.status.idle":"2024-02-24T06:37:52.693982Z","shell.execute_reply.started":"2024-02-24T06:36:40.692285Z","shell.execute_reply":"2024-02-24T06:37:52.692863Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef344411410422b9f47059baafde65b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26909 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11cd636746a04a22a9950b5cc981f5e3"}},"metadata":{}}]},{"cell_type":"code","source":"def dummy(text):\n    return text\n\nvectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, analyzer = 'word',\n    tokenizer = dummy,\n    preprocessor = dummy,\n    token_pattern = None, strip_accents='unicode')\n\nvectorizer.fit(tokenized_texts_test)\n\n# Getting vocab\nvocab = vectorizer.vocabulary_\n\n# print(vocab)\n\nvectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n                            analyzer = 'word',\n                            tokenizer = dummy,\n                            preprocessor = dummy,\n                            token_pattern = None, strip_accents='unicode'\n                            )\n\ntf_train = vectorizer.fit_transform(tokenized_texts_train)\ntf_test = vectorizer.transform(tokenized_texts_test)\n\ndel vectorizer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:37:52.695598Z","iopub.execute_input":"2024-02-24T06:37:52.699778Z","iopub.status.idle":"2024-02-24T06:40:42.428843Z","shell.execute_reply.started":"2024-02-24T06:37:52.699731Z","shell.execute_reply":"2024-02-24T06:40:42.427911Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"code","source":"y_train = train['label'].values","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:40:42.429957Z","iopub.execute_input":"2024-02-24T06:40:42.431905Z","iopub.status.idle":"2024-02-24T06:40:42.437672Z","shell.execute_reply.started":"2024-02-24T06:40:42.431858Z","shell.execute_reply":"2024-02-24T06:40:42.436528Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_model():\n\n    mnb_model = MultinomialNB(alpha=1)\n\n    sgd_model = SGDClassifier(max_iter=9000, tol=1e-4, loss=\"modified_huber\", random_state=6743)\n\n    param = {\n        'n_iter': 3000,\n        'verbose': -1,\n        'objective': 'cross_entropy',\n        'metric': 'auc',\n        'learning_rate': 0.00581909898961407, \n        'colsample_bytree': 0.78,\n        'colsample_bynode': 0.5,\n        'random_state': 6743\n       }\n    lgb_model = LGBMClassifier(**param)\n\n    cat_model = CatBoostClassifier(\n#         iterations=3000,\n        iterations=1200,\n        verbose=0,\n        random_seed=6543,\n#         learning_rate=0.005599066836106983,\n        learning_rate=0.01,\n        subsample = 0.35,\n        allow_const_label=True,\n        loss_function = 'CrossEntropy'\n    )\n    \n    weights = [0.1,0.31,0.28,0.67]\n \n    ensemble = VotingClassifier(estimators=[\n        ('mnb_model', mnb_model),\n        ('sgd_model', sgd_model),\n        ('lgb_model', lgb_model), \n        ('cat_model', cat_model)\n        ],\n                                weights=weights, voting='soft', n_jobs=-1)\n    return ensemble","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:40:42.439101Z","iopub.execute_input":"2024-02-24T06:40:42.439536Z","iopub.status.idle":"2024-02-24T06:40:42.454322Z","shell.execute_reply.started":"2024-02-24T06:40:42.439497Z","shell.execute_reply":"2024-02-24T06:40:42.453270Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nprint(model)\n\nif len(test.text.values) <= 5:\n    # if not, just sample submission\n    sub.to_csv('submission.csv', index=False)\nelse:\n    model.fit(tf_train, y_train)\n\n    final_preds = model.predict_proba(tf_test)[:,1]\n    sub['generated'] = final_preds\n    sub.to_csv('submission.csv', index=False)\n    sub","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:40:42.456166Z","iopub.execute_input":"2024-02-24T06:40:42.456647Z","iopub.status.idle":"2024-02-24T06:40:42.487414Z","shell.execute_reply.started":"2024-02-24T06:40:42.456605Z","shell.execute_reply":"2024-02-24T06:40:42.486272Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"VotingClassifier(estimators=[('mnb_model', MultinomialNB(alpha=1)),\n                             ('sgd_model',\n                              SGDClassifier(loss='modified_huber',\n                                            max_iter=9000, random_state=6743,\n                                            tol=0.0001)),\n                             ('lgb_model',\n                              LGBMClassifier(colsample_bynode=0.5,\n                                             colsample_bytree=0.78,\n                                             learning_rate=0.00581909898961407,\n                                             metric='auc', n_iter=3000,\n                                             objective='cross_entropy',\n                                             random_state=6743, verbose=-1)),\n                             ('cat_model',\n                              <catboost.core.CatBoostClassifier object at 0x7b88a4f1cc40>)],\n                 n_jobs=-1, voting='soft', weights=[0.1, 0.31, 0.28, 0.67])\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}